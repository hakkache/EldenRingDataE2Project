{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e38376f9-ecfc-457b-b189-9940fa07cf4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Get all tables from the schema\n",
    "# tables = spark.catalog.listTables(\"eldenringcatalog.silver\")\n",
    "\n",
    "# for t in tables:\n",
    "#     table_name = f\"eldenringcatalog.silver.{t.name}\"\n",
    "#     print(f\"Dropping table: {table_name}\")\n",
    "#     spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38402198-0851-4ccd-bd2a-0021f8fba2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "###**1-IMPORTS AND CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38d15756-a962-45dd-85b1-959bf9475e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, lit, current_timestamp, when, coalesce, explode, split,\n",
    "    from_json, regexp_extract, regexp_replace, trim, upper, lower,\n",
    "    udf, struct, array, size, concat_ws, substring,expr,\n",
    "    sum as spark_sum, count as spark_count,\n",
    "    monotonically_increasing_id, row_number)\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, \n",
    "    DoubleType, BooleanType, ArrayType, MapType\n",
    ")\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "import logging\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional,Any\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22694672-b7c6-4d19-8640-c42feedef8d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9680882-66ba-4203-9a8c-1feae9289c92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"catalog\": \"eldenringcatalog\",\n",
    "    \"bronze_schema\": \"bronze\",\n",
    "    \"silver_schema\": \"silver\",\n",
    "    \"checkpoint_path\": \"/mnt/delta/checkpoints/silver/\",\n",
    "    \"batch_id\": datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f78af2-b7a2-4863-ab1c-0dbe93e8b903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "###**2-UNIVERSAL DICT PARSER (Handles Python dict strings and clean numeric values)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c23a256a-7f2b-4a59-b87b-25120564aa74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def safe_parse_dict(dict_str: str) -> Dict[str, str]:\n",
    "    \"parser for Python dict strings\"\n",
    "\n",
    "    if not dict_str or dict_str in ['null', 'None', '-', '']:\n",
    "        return {}\n",
    "    \n",
    "    try :\n",
    "        # Remove extra whitespace and standardize\n",
    "        cleaned = dict_str.strip()\n",
    "\n",
    "        # Handle list wrapper [{}]\n",
    "        if cleaned.startswith('[') and cleaned.endswith(']'):\n",
    "            cleaned = cleaned[1:-1].strip()\n",
    "            # If multiple dicts in list, take first one\n",
    "            if '},{' in cleaned:\n",
    "                cleaned = cleaned.split('},{')[0] + '}'\n",
    "        \n",
    "        # Try ast.literal_eval (safest for Python dicts)\n",
    "        try:\n",
    "            parsed = ast.literal_eval(cleaned)\n",
    "            if isinstance(parsed, dict):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, list) and len(parsed) > 0:\n",
    "                return parsed[0] if isinstance(parsed[0], dict) else {}\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Try json.loads as fallback\n",
    "        try :\n",
    "            parsed = json.loads(cleaned)\n",
    "            if isinstance(parsed, dict):\n",
    "                return parsed\n",
    "            elif isinstance(parsed, list) and len(parsed) > 0:\n",
    "                return parsed[0] if isinstance(parsed[0], dict) else {}\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Manual regex parsing as last resort\n",
    "\n",
    "        if '{' in cleaned and '}' in cleaned:\n",
    "            # Extract key-value pairs\n",
    "            pattern = r\"['\\\"]?(\\w+(?:\\s+\\w+\\.?)?)['\\\"]?\\s*:\\s*['\\\"]?([^,'\\\"]+)['\\\"]?\"\n",
    "            matches = re.findall(pattern, cleaned)\n",
    "            if matches:\n",
    "                return {k.strip(): v.strip() for k, v in matches}\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to parse dict: {dict_str[:100]} - {e}\")\n",
    "        return {}    \n",
    "            \n",
    "def clean_numeric_value(value: str) -> Optional[float]:\n",
    "    \"Clean and convert string numbers to float\"\n",
    "    if not value or value in ['-', 'null', 'None']:\n",
    "        return None\n",
    "    try:\n",
    "         # Remove spaces and convert\n",
    "        cleaned = str(value).strip()\n",
    "        return float(cleaned) if cleaned else None\n",
    "    except :\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21250a08-08a2-4cfe-a7ef-bf0bd9f1706f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0c39601-3883-42f1-878e-8a6be391732b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **3-STAT PARSING UDFs (With correct key mappings)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "970c706e-8716-4033-93be-06a2876b88b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_attack_stats(attack_str: str) -> Dict[str, int]:\n",
    "\n",
    "    \"Parse attack stats - handles multiple key names\"\n",
    "    default = {'physical': 0, 'magic': 0, 'fire': 0, 'lightning': 0, 'holy': 0, 'stamina': 0, 'critical': 0}\n",
    "\n",
    "    parsed = safe_parse_dict(attack_str)\n",
    "    if not parsed:\n",
    "        return default\n",
    "    \n",
    "    # Key mapping (handles different abbreviations)\n",
    "    key_map = {\n",
    "        'phy': 'physical', 'physical': 'physical',\n",
    "        'mag': 'magic', 'magic': 'magic',\n",
    "        'fir': 'fire', 'fire': 'fire',\n",
    "        'lit': 'lightning', 'lig': 'lightning', 'lightning': 'lightning',\n",
    "        'hol': 'holy', 'holy': 'holy',\n",
    "        'sta': 'stamina', 'stamina': 'stamina',\n",
    "        'cri': 'critical', 'critical': 'critical'\n",
    "    }\n",
    "\n",
    "    for key, value in parsed.items():\n",
    "        key_lower = key.lower().strip()[:3]  # First 3 chars\n",
    "        if key_lower in key_map:\n",
    "            stat_name = key_map[key_lower]\n",
    "            cleaned_val = clean_numeric_value(value)\n",
    "            if cleaned_val is not None:\n",
    "                default[stat_name] = int(cleaned_val)\n",
    "\n",
    "    return default\n",
    "\n",
    "\n",
    "def parse_defense_stats(defense_str: str) -> Dict[str, float]:\n",
    "\n",
    "    \"Parse defense/guard stats\"\n",
    "\n",
    "    default = {'physical': 0.0, 'magic': 0.0, 'fire': 0.0, 'lightning': 0.0, 'holy': 0.0, 'boost': 0.0,'resistance': 0.0}\n",
    "\n",
    "    parsed = safe_parse_dict(defense_str)\n",
    "\n",
    "    if not parsed:\n",
    "        return default\n",
    "    \n",
    "    key_map = {\n",
    "        'phy': 'physical',\n",
    "        'mag': 'magic',\n",
    "        'fir': 'fire',\n",
    "        'lit': 'lightning', 'lig': 'lightning',\n",
    "        'hol': 'holy',\n",
    "        'bst': 'boost', 'boost': 'boost', 'gua': 'boost',\n",
    "        'rst': 'resistance', 'resistance': 'resistance'  # NEW: Added Rst\n",
    "    }\n",
    "\n",
    "    for key, value in parsed.items():\n",
    "        key_lower = key.lower().strip()[:3]\n",
    "        if key_lower in key_map:\n",
    "            stat_name = key_map[key_lower]\n",
    "            cleaned_val = clean_numeric_value(value)\n",
    "            if cleaned_val is not None:\n",
    "                default[stat_name] = float(cleaned_val)\n",
    "    \n",
    "    return default\n",
    "\n",
    "def parse_dmg_negation_stats(negation_str: str) -> Dict[str, float]:\n",
    "\n",
    "    \"Parse damage negation (armor) - handles extended format\"\n",
    "\n",
    "    default = {\n",
    "        'physical': 0.0, 'vs_strike': 0.0, 'vs_slash': 0.0, 'vs_pierce': 0.0,\n",
    "        'magic': 0.0, 'fire': 0.0, 'lightning': 0.0, 'holy': 0.0\n",
    "    }\n",
    "\n",
    "    parsed = safe_parse_dict(negation_str)\n",
    "    if not parsed:\n",
    "        return default\n",
    "    \n",
    "    for key, value in parsed.items():\n",
    "        key_clean = key.lower().strip()\n",
    "        cleaned_val = clean_numeric_value(value)\n",
    "\n",
    "        if cleaned_val is None:\n",
    "            continue\n",
    "\n",
    "        if key_clean.startswith('phy'):\n",
    "            default['physical'] = float(cleaned_val)\n",
    "        elif 'str' in key_clean:\n",
    "            default['vs_strike'] = float(cleaned_val)\n",
    "        elif 'sla' in key_clean:\n",
    "            default['vs_slash'] = float(cleaned_val)\n",
    "        elif 'pie' in key_clean:\n",
    "            default['vs_pierce'] = float(cleaned_val)\n",
    "        elif key_clean.startswith('mag'):\n",
    "            default['magic'] = float(cleaned_val)\n",
    "        elif key_clean.startswith('fir'):\n",
    "            default['fire'] = float(cleaned_val)\n",
    "        elif key_clean.startswith('lit') or key_clean.startswith('lig'):\n",
    "            default['lightning'] = float(cleaned_val)\n",
    "        elif key_clean.startswith('hol'):\n",
    "            default['holy'] = float(cleaned_val)\n",
    "    \n",
    "    return default\n",
    "\n",
    "def parse_scaling_stats(scaling_str: str) -> Dict[str, str]:\n",
    "    \"Parse scaling grades\"\n",
    "\n",
    "    default = {'str': '-', 'dex': '-', 'int': '-', 'fai': '-', 'arc': '-'}\n",
    "\n",
    "    parsed = safe_parse_dict(scaling_str)\n",
    "    if not parsed:\n",
    "        return default\n",
    "    \n",
    "    for key, value in parsed.items():\n",
    "        key_lower = key.lower().strip()[:3]\n",
    "        if key_lower in default:\n",
    "            default[key_lower] = str(value).strip() if value else '-'\n",
    "    \n",
    "    return default\n",
    "\n",
    "def parse_requirements_stats(req_str: str) -> Dict[str, int]:\n",
    "    \"Parse attribute requirements\"\n",
    "    default = {'str': 0, 'dex': 0, 'int': 0, 'fai': 0, 'arc': 0}\n",
    "    parsed = safe_parse_dict(req_str)\n",
    "    if not parsed:\n",
    "        return default\n",
    "    \n",
    "    for key, value in parsed.items():\n",
    "        key_lower = key.lower().strip()[:3]\n",
    "        if key_lower in default:\n",
    "            cleaned_val = clean_numeric_value(value)\n",
    "            if cleaned_val is not None:\n",
    "                default[key_lower] = int(cleaned_val)\n",
    "    \n",
    "    return default\n",
    "\n",
    "\n",
    "def parse_resistance_stats(resistance_str: str) -> Dict[str, float]:\n",
    "    \"Parse resistance stats (armor)\"\n",
    "\n",
    "    default = {'immunity': 0.0, 'robustness': 0.0, 'focus': 0.0, 'vitality': 0.0, 'poise': 0.0}\n",
    "\n",
    "    parsed = safe_parse_dict(resistance_str)\n",
    "    if not parsed:\n",
    "        return default\n",
    "    \n",
    "    key_map = {\n",
    "        'imm': 'immunity', 'immunity': 'immunity',\n",
    "        'rob': 'robustness', 'robustness': 'robustness',\n",
    "        'foc': 'focus', 'focus': 'focus',\n",
    "        'vit': 'vitality', 'vitality': 'vitality',\n",
    "        'poi': 'poise', 'poise': 'poise'\n",
    "    }\n",
    "     \n",
    "    for key, value in parsed.items():\n",
    "        key_lower = key.lower().strip()[:3]\n",
    "        if key_lower in key_map:\n",
    "            stat_name = key_map[key_lower]\n",
    "            cleaned_val = clean_numeric_value(value)\n",
    "            if cleaned_val is not None:\n",
    "                default[stat_name] = float(cleaned_val)\n",
    "    \n",
    "    return default\n",
    "def parse_fp_cost(fp_str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Parse FP cost from all possible formats in Elden Ring dataset\n",
    "    \n",
    "    Input formats and their meaning:\n",
    "    1. 0 or \"0\" → No FP cost\n",
    "    2. 6 or \"6\" → Single fixed cost (6 FP)\n",
    "    3. \"10 - 25\" → Dual mode: 10 FP (light), 25 FP (heavy)\n",
    "    4. \"6 (-12)\" → Combo: 6 FP initial, 12 FP follow-up\n",
    "    5. \"- (6 8)\" → Multi-phase: 6 FP or 8 FP\n",
    "    6. \"2 (per swing)\" → Continuous: 2 FP per hit/tick\n",
    "    7. \"- 6\" → Badly formatted, treat as 6 FP\n",
    "    \n",
    "    Output: {'min': int, 'max': int, 'per_use': int, 'type': str}\n",
    "    \"\"\"\n",
    "    default = {'min': 0, 'max': 0, 'per_use': 0, 'type': 'none'}\n",
    "    \n",
    "    # Handle None/null\n",
    "    if fp_str is None:\n",
    "        return default\n",
    "    \n",
    "    # Handle numeric types (int/float)\n",
    "    if isinstance(fp_str, (int, float)):\n",
    "        cost = int(fp_str)\n",
    "        return {\n",
    "            'min': cost,\n",
    "            'max': cost,\n",
    "            'per_use': 0,\n",
    "            'type': 'single'\n",
    "        }\n",
    "    \n",
    "    # Convert to string for string operations\n",
    "    try:\n",
    "        cleaned = str(fp_str).strip().lower()\n",
    "    except:\n",
    "        return default\n",
    "    \n",
    "    # Handle empty/dash values\n",
    "    if not cleaned or cleaned in ['-', '', 'null', 'none', 'nan']:\n",
    "        return default\n",
    "    \n",
    "    try:\n",
    "        # PATTERN 1: \"2 (per swing)\" or \"3 (per hit)\"\n",
    "        if 'per swing' in cleaned or 'per hit' in cleaned or 'per tick' in cleaned:\n",
    "            match = re.search(r'(\\d+)', cleaned)\n",
    "            if match:\n",
    "                per_use_cost = int(match.group(1))\n",
    "                return {\n",
    "                    'min': per_use_cost,\n",
    "                    'max': per_use_cost,\n",
    "                    'per_use': per_use_cost,\n",
    "                    'type': 'continuous'\n",
    "                }\n",
    "        \n",
    "        # PATTERN 2: \"10 - 25\" (dual mode: light/heavy)\n",
    "        if ' - ' in cleaned or ' – ' in cleaned:\n",
    "            parts = re.findall(r'\\d+', cleaned)\n",
    "            if len(parts) >= 2:\n",
    "                return {\n",
    "                    'min': int(parts[0]),\n",
    "                    'max': int(parts[1]),\n",
    "                    'per_use': 0,\n",
    "                    'type': 'dual'\n",
    "                }\n",
    "        \n",
    "        # PATTERN 3: \"6 (-12)\" or \"5(-8)\" (combo: initial + follow-up)\n",
    "        match = re.search(r'(\\d+)\\s*\\(\\s*-?\\s*(\\d+)\\s*\\)', cleaned)\n",
    "        if match:\n",
    "            initial = int(match.group(1))\n",
    "            followup = int(match.group(2))\n",
    "            return {\n",
    "                'min': initial,\n",
    "                'max': followup,\n",
    "                'per_use': 0,\n",
    "                'type': 'combo'\n",
    "            }\n",
    "        \n",
    "        # PATTERN 4: \"- (6 8)\" or \"(6 8)\" (multi-phase)\n",
    "        match = re.search(r'\\(\\s*(\\d+)\\s+(\\d+)\\s*\\)', cleaned)\n",
    "        if match:\n",
    "            phase1 = int(match.group(1))\n",
    "            phase2 = int(match.group(2))\n",
    "            return {\n",
    "                'min': min(phase1, phase2),\n",
    "                'max': max(phase1, phase2),\n",
    "                'per_use': 0,\n",
    "                'type': 'multiphase'\n",
    "            }\n",
    "        \n",
    "        # PATTERN 5: Single number (including \"- 6\" badly formatted)\n",
    "        # Extract ALL numbers and take the first valid one\n",
    "        numbers = [int(n) for n in re.findall(r'\\d+', cleaned)]\n",
    "        if numbers:\n",
    "            cost = numbers[0]\n",
    "            return {\n",
    "                'min': cost,\n",
    "                'max': cost,\n",
    "                'per_use': 0,\n",
    "                'type': 'single'\n",
    "            }\n",
    "        \n",
    "        return default\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to parse FP cost: {fp_str} - {e}\")\n",
    "        return default\n",
    "\n",
    "def parse_boss_hp(hp_str) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Parse boss HP from various formats\n",
    "    \n",
    "    Handles:\n",
    "    1. \"22,571\" → single HP\n",
    "    2. \"7,560 (phase 1) 13,608 (phase 2)\" → multi-phase\n",
    "    3. \"≈ 13,339 (GOD)\" → approximate with classification\n",
    "    4. \"TBD\" → unknown\n",
    "    5. None/empty → 0\n",
    "    \n",
    "    Returns: {'hp_min': int, 'hp_max': int, 'hp_type': str, 'phases': int, 'classification': str}\n",
    "    \"\"\"\n",
    "    default = {\n",
    "        'hp_min': 0,\n",
    "        'hp_max': 0,\n",
    "        'hp_type': 'unknown',\n",
    "        'phases': 1,\n",
    "        'classification': 'Normal'\n",
    "    }\n",
    "    \n",
    "    # Handle None, null, TBD\n",
    "    if not hp_str or hp_str in ['TBD', 'null', 'None', '']:\n",
    "        return default\n",
    "    \n",
    "    # Handle numeric types\n",
    "    if isinstance(hp_str, (int, float)):\n",
    "        hp_val = int(hp_str)\n",
    "        return {\n",
    "            'hp_min': hp_val,\n",
    "            'hp_max': hp_val,\n",
    "            'hp_type': 'single',\n",
    "            'phases': 1,\n",
    "            'classification': 'Normal'\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        hp_clean = str(hp_str).strip()\n",
    "        \n",
    "        # PATTERN 1: Approximate with classification \"≈ 13,339 (GOD)\"\n",
    "        if '≈' in hp_clean:\n",
    "            classification_match = re.search(r'\\(([^)]+)\\)', hp_clean)\n",
    "            classification = classification_match.group(1) if classification_match else 'Approximate'\n",
    "            \n",
    "            numbers = re.findall(r'[\\d,]+', hp_clean.replace('≈', ''))\n",
    "            if numbers:\n",
    "                hp_value = int(numbers[0].replace(',', ''))\n",
    "                return {\n",
    "                    'hp_min': hp_value,\n",
    "                    'hp_max': hp_value,\n",
    "                    'hp_type': 'approximate',\n",
    "                    'phases': 1,\n",
    "                    'classification': classification\n",
    "                }\n",
    "        \n",
    "        # PATTERN 2: Phase-based \"7,560 (phase 1) 13,608 (phase 2)\"\n",
    "        if 'phase' in hp_clean.lower():\n",
    "            phase_matches = re.findall(r'([\\d,]+)\\s*\\(phase\\s+\\d+\\)', hp_clean, re.IGNORECASE)\n",
    "            if phase_matches:\n",
    "                hp_values = [int(m.replace(',', '')) for m in phase_matches]\n",
    "                return {\n",
    "                    'hp_min': min(hp_values),\n",
    "                    'hp_max': max(hp_values),\n",
    "                    'hp_type': 'phased',\n",
    "                    'phases': len(hp_values),\n",
    "                    'classification': 'Multi-Phase'\n",
    "                }\n",
    "        \n",
    "        # PATTERN 3: Classification in parentheses\n",
    "        classification_match = re.search(r'\\(([^)]+)\\)', hp_clean)\n",
    "        classification = classification_match.group(1) if classification_match else 'Normal'\n",
    "        \n",
    "        # PATTERN 4: Simple numeric with commas \"22,571\"\n",
    "        numbers = re.findall(r'[\\d,]+', hp_clean)\n",
    "        if numbers:\n",
    "            hp_value = int(numbers[0].replace(',', ''))\n",
    "            return {\n",
    "                'hp_min': hp_value,\n",
    "                'hp_max': hp_value,\n",
    "                'hp_type': 'single',\n",
    "                'phases': 1,\n",
    "                'classification': classification\n",
    "            }\n",
    "        \n",
    "        return default\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to parse HP: {hp_str} - {e}\")\n",
    "        return default\n",
    "    \n",
    "def parse_passive_effects(effects_str: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse passive effects JSON string to structured dict\n",
    "    \n",
    "    Handles all formats:\n",
    "    - \"{'Any': '- '}\"                          → No effect\n",
    "    - \"{'Any': '(66) Frostbite'}\"             → Single buildup: 66\n",
    "    - \"{'Any': '(88)(38) Poison'}\"            → Dual buildup: 88 primary, 38 secondary\n",
    "    - \"{'Any': '(73)(38) Frostbite'}\"         → Dual buildup: 73 primary, 38 secondary\n",
    "    - \"{'Any': '(66) Frostbite (45) Poison'}\" → Multiple different effects\n",
    "    \n",
    "    Output: {\n",
    "        'effect_type': 'poison',             # Effect name\n",
    "        'buildup_primary': 88,               # Primary buildup value\n",
    "        'buildup_secondary': 38,             # Secondary buildup value (0 if none)\n",
    "        'has_dual_buildup': True,            # Flag for dual values\n",
    "        'has_effect': True                   # Boolean flag\n",
    "    }\n",
    "    \"\"\"\n",
    "    default_result = {\n",
    "        'effect_type': None,\n",
    "        'buildup_primary': 0,\n",
    "        'buildup_secondary': 0,\n",
    "        'has_dual_buildup': False,\n",
    "        'has_effect': False\n",
    "    }\n",
    "    \n",
    "    if not effects_str or effects_str == 'null' or str(effects_str).strip() == '':\n",
    "        return default_result\n",
    "    \n",
    "    try:\n",
    "        # Clean and parse JSON\n",
    "        cleaned = str(effects_str).replace(\"'\", '\"').strip()\n",
    "        effects_dict = json.loads(cleaned)\n",
    "        \n",
    "        # Get the 'Any' value\n",
    "        effect_value = effects_dict.get('Any', '').strip()\n",
    "        \n",
    "        # Check if no effect\n",
    "        if effect_value == '-' or effect_value == '' or effect_value == '- ':\n",
    "            return default_result\n",
    "        \n",
    "        import re\n",
    "        \n",
    "        # Pattern 1: Dual buildup with SAME effect type\n",
    "        # Example: \"(88)(38) Poison\" or \"(73)(38) Frostbite\"\n",
    "        dual_match = re.search(r'\\((\\d+)\\)\\((\\d+)\\)\\s*([A-Za-z\\s]+)$', effect_value)\n",
    "        \n",
    "        if dual_match:\n",
    "            primary_buildup = int(dual_match.group(1))\n",
    "            secondary_buildup = int(dual_match.group(2))\n",
    "            effect_name = dual_match.group(3).strip().lower()\n",
    "            \n",
    "            # Normalize effect names\n",
    "            effect_mapping = {\n",
    "                'hemorrhage': 'bleed',\n",
    "                'scarlet rot': 'scarlet_rot',\n",
    "                'death': 'death_blight'\n",
    "            }\n",
    "            effect_name = effect_mapping.get(effect_name, effect_name)\n",
    "            \n",
    "            return {\n",
    "                'effect_type': effect_name,\n",
    "                'buildup_primary': primary_buildup,\n",
    "                'buildup_secondary': secondary_buildup,\n",
    "                'has_dual_buildup': True,\n",
    "                'has_effect': True\n",
    "            }\n",
    "        \n",
    "        # Pattern 2: Single buildup value\n",
    "        # Example: \"(66) Frostbite\" or \"(57) Hemorrhage\"\n",
    "        single_match = re.search(r'\\((\\d+)\\)\\s*([A-Za-z\\s]+)', effect_value)\n",
    "        \n",
    "        if single_match:\n",
    "            buildup = int(single_match.group(1))\n",
    "            effect_name = single_match.group(2).strip().lower()\n",
    "            \n",
    "            # Normalize effect names\n",
    "            effect_mapping = {\n",
    "                'hemorrhage': 'bleed',\n",
    "                'scarlet rot': 'scarlet_rot',\n",
    "                'death': 'death_blight'\n",
    "            }\n",
    "            effect_name = effect_mapping.get(effect_name, effect_name)\n",
    "            \n",
    "            return {\n",
    "                'effect_type': effect_name,\n",
    "                'buildup_primary': buildup,\n",
    "                'buildup_secondary': 0,\n",
    "                'has_dual_buildup': False,\n",
    "                'has_effect': True\n",
    "            }\n",
    "        \n",
    "        return default_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to parse passive effects: {effects_str[:100]}... - {e}\")\n",
    "        return default_result\n",
    "\n",
    "fp_cost_schema = StructType([\n",
    "    StructField(\"min\", IntegerType(), False),\n",
    "    StructField(\"max\", IntegerType(), False),\n",
    "    StructField(\"per_use\", IntegerType(), False),\n",
    "    StructField(\"type\", StringType(), False)\n",
    "])\n",
    "\n",
    "hp_schema = StructType([\n",
    "    StructField(\"hp_min\", IntegerType(), False),\n",
    "    StructField(\"hp_max\", IntegerType(), False),\n",
    "    StructField(\"hp_type\", StringType(), False),\n",
    "    StructField(\"phases\", IntegerType(), False),\n",
    "    StructField(\"classification\", StringType(), False)\n",
    "])\n",
    "\n",
    "passive_effects_schema = StructType([\n",
    "    StructField('effect_type', StringType(), True),\n",
    "    StructField('buildup_primary', IntegerType(), True),\n",
    "    StructField('buildup_secondary', IntegerType(), True),\n",
    "    StructField('has_dual_buildup', BooleanType(), True),\n",
    "    StructField('has_effect', BooleanType(), True)\n",
    "])\n",
    "# Register UDFs\n",
    "parse_attack_udf = udf(parse_attack_stats, MapType(StringType(), IntegerType()))\n",
    "parse_defense_udf = udf(parse_defense_stats, MapType(StringType(), DoubleType()))\n",
    "parse_negation_udf = udf(parse_dmg_negation_stats, MapType(StringType(), DoubleType()))\n",
    "parse_scaling_udf = udf(parse_scaling_stats, MapType(StringType(), StringType()))\n",
    "parse_required_udf = udf(parse_requirements_stats, MapType(StringType(), IntegerType()))\n",
    "parse_resistance_udf = udf(parse_resistance_stats, MapType(StringType(), DoubleType()))   \n",
    "parse_fp_udf = udf(parse_fp_cost, fp_cost_schema)  \n",
    "parse_boss_hp_udf = udf(parse_boss_hp, hp_schema)   \n",
    "parse_passive_effects_udf = udf(parse_passive_effects, passive_effects_schema)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebb27c9-f993-48d8-b10d-47de04c11bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **4-SILVER TRANSFORMATIONS - ALL 28 TABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1137bf1-3e84-4ff2-89bd-07ee771b9a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SilverTransformer:\n",
    "    \"\"\"Handles ALL transformations from Bronze to Silver\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.catalog = config[\"catalog\"]\n",
    "        self.bronze_schema = config[\"bronze_schema\"]\n",
    "        self.bronze_schema = config[\"bronze_schema\"]\n",
    "    \n",
    "    def transform_weapons(self) -> DataFrame:\n",
    "        \"\"\"Transform weapons (table 1/28)\"\"\"\n",
    "        logger.info(\"Transforming weapons...\")\n",
    "\n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.weapons\")\n",
    "\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"required_parsed\", parse_required_udf(col(\"requirements\"))) \\\n",
    "            .withColumn(\"fp_parsed\", parse_fp_udf(col(\"fp_cost\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"weapon_id\"),\n",
    "            col(\"name\").alias(\"weapon_name\"),\n",
    "            col(\"category\"),\n",
    "            coalesce(col(\"weight\").cast(DoubleType()), lit(0.0)).alias(\"weight\"),\n",
    "            col(\"description\"),\n",
    "            col(\"image\"),\n",
    "            col(\"skill\"),\n",
    "           # FP cost structure\n",
    "            col(\"fp_parsed.min\").alias(\"fp_cost_min\"),\n",
    "            col(\"fp_parsed.max\").alias(\"fp_cost_max\"),\n",
    "            col(\"fp_parsed.per_use\").alias(\"fp_cost_per_use\"),\n",
    "            col(\"fp_parsed.type\").alias(\"fp_cost_type\"),\n",
    "            col(\"damage_type\"),\n",
    "            col(\"passive_effect\"),\n",
    "            # Requirements only (no attack/scaling in base weapons.csv)\n",
    "            coalesce(col(\"required_parsed\")['str'], lit(0)).alias(\"required_str\"),\n",
    "            coalesce(col(\"required_parsed\")['dex'], lit(0)).alias(\"required_dex\"),\n",
    "            coalesce(col(\"required_parsed\")['int'], lit(0)).alias(\"required_int\"),\n",
    "            coalesce(col(\"required_parsed\")['fai'], lit(0)).alias(\"required_fai\"),\n",
    "            coalesce(col(\"required_parsed\")['arc'], lit(0)).alias(\"required_arc\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "\n",
    "        logger.info(f\"  ✅ {df_silver.count():,} weapons\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_shields(self) -> DataFrame:\n",
    "        \"\"\"Transform shields (table 2/28)\"\"\"\n",
    "        logger.info(\"Transforming shields...\")\n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.shields\")\n",
    "\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"required_parsed\", parse_required_udf(col(\"requirements\")))\\\n",
    "            .withColumn(\"fp_parsed\", parse_fp_udf(col(\"fp_cost\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"shield_id\"),\n",
    "            col(\"name\").alias(\"shield_name\"),\n",
    "            col(\"category\"),\n",
    "            coalesce(col(\"weight\").cast(DoubleType()), lit(0.0)).alias(\"weight\"),\n",
    "            col(\"description\"),\n",
    "            col(\"image\"),\n",
    "            col(\"skill\"),\n",
    "            coalesce(col(\"fp_cost\").cast(DoubleType()), lit(0.0)).alias(\"fp_cost\"),\n",
    "            col(\"damage_type\"),\n",
    "            col(\"passive_effect\"),\n",
    "            # Requirements\n",
    "            col(\"fp_parsed.min\").alias(\"fp_cost_min\"),\n",
    "            col(\"fp_parsed.max\").alias(\"fp_cost_max\"),\n",
    "            col(\"fp_parsed.per_use\").alias(\"fp_cost_per_use\"),\n",
    "            col(\"fp_parsed.type\").alias(\"fp_cost_type\"),\n",
    "            coalesce(col(\"required_parsed\")['str'], lit(0)).alias(\"required_str\"),\n",
    "            coalesce(col(\"required_parsed\")['dex'], lit(0)).alias(\"required_dex\"),\n",
    "            coalesce(col(\"required_parsed\")['int'], lit(0)).alias(\"required_int\"),\n",
    "            coalesce(col(\"required_parsed\")['fai'], lit(0)).alias(\"required_fai\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} shields\")\n",
    "        return df_silver\n",
    "\n",
    "    def transform_armors(self) -> DataFrame:\n",
    "        \"\"\"Transform armors (table 3/28)\"\"\"\n",
    "        logger.info(\"Transforming armors...\")\n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.armors\")\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"negation_parsed\", parse_negation_udf(col(\"damage_negation\"))) \\\n",
    "            .withColumn(\"resistance_parsed\", parse_resistance_udf(col(\"resistance\")))\n",
    "    \n",
    "\n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"armor_id\"),\n",
    "            col(\"name\").alias(\"armor_name\"),\n",
    "            col(\"type\").alias(\"category\"),\n",
    "            coalesce(col(\"weight\").cast(DoubleType()), lit(0.0)).alias(\"weight\"),\n",
    "            col(\"description\"),\n",
    "            col(\"image\"),\n",
    "            # Damage negation\n",
    "            coalesce(col(\"negation_parsed\")['physical'], lit(0.0)).alias(\"dmg_negation_physical\"),\n",
    "            coalesce(col(\"negation_parsed\")['vs_strike'], lit(0.0)).alias(\"dmg_negation_vs_strike\"),\n",
    "            coalesce(col(\"negation_parsed\")['vs_slash'], lit(0.0)).alias(\"dmg_negation_vs_slash\"),\n",
    "            coalesce(col(\"negation_parsed\")['vs_pierce'], lit(0.0)).alias(\"dmg_negation_vs_pierce\"),\n",
    "            coalesce(col(\"negation_parsed\")['magic'], lit(0.0)).alias(\"dmg_negation_magic\"),\n",
    "            coalesce(col(\"negation_parsed\")['fire'], lit(0.0)).alias(\"dmg_negation_fire\"),\n",
    "            coalesce(col(\"negation_parsed\")['lightning'], lit(0.0)).alias(\"dmg_negation_lightning\"),\n",
    "            coalesce(col(\"negation_parsed\")['holy'], lit(0.0)).alias(\"dmg_negation_holy\"),\n",
    "            # Resistances\n",
    "            coalesce(col(\"resistance_parsed\")['immunity'], lit(0.0)).alias(\"resistance_immunity\"),\n",
    "            coalesce(col(\"resistance_parsed\")['robustness'], lit(0.0)).alias(\"resistance_robustness\"),\n",
    "            coalesce(col(\"resistance_parsed\")['focus'], lit(0.0)).alias(\"resistance_focus\"),\n",
    "            coalesce(col(\"resistance_parsed\")['vitality'], lit(0.0)).alias(\"resistance_vitality\"),\n",
    "            coalesce(col(\"resistance_parsed\")['poise'], lit(0.0)).alias(\"resistance_poise\"),\n",
    "            # DLC flag - inline mapping for \"Base Game\" → 0, everything else → 1\n",
    "            when(col(\"dlc\").isNull(), lit(0))\n",
    "            .when(lower(col(\"dlc\")).contains(\"base\"), lit(0))\n",
    "            .when(lower(col(\"dlc\")) == \"0\", lit(0))\n",
    "            .otherwise(lit(1))\n",
    "            .alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} armors\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_bosses(self) -> DataFrame:\n",
    "        \"\"\"Transform bosses (table 4/28)\"\"\"\n",
    "        logger.info(\"Transforming bosses...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.bosses\")\n",
    "        df_parsed = df.withColumn(\"hp_parsed\", parse_boss_hp_udf(col(\"hp\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"boss_id\"),\n",
    "            col(\"name\").alias(\"boss_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"hp_parsed.hp_min\").alias(\"hp_min\"),\n",
    "            col(\"hp_parsed.hp_max\").alias(\"hp_max\"),\n",
    "            col(\"hp_parsed.hp_type\").alias(\"hp_type\"),\n",
    "            col(\"hp_parsed.phases\").alias(\"phase_count\"),\n",
    "            col(\"hp_parsed.classification\").alias(\"boss_classification\"),\n",
    "            col(\"locations_&_drops\").alias(\"locations_and_drops\"),\n",
    "            col(\"blockquote\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} bosses\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_npcs(self) -> DataFrame:\n",
    "        \"\"\"Transform NPCs (table 5/28)\"\"\"\n",
    "        logger.info(\"Transforming NPCs...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.npcs\")\n",
    "        \n",
    "        df_silver = df.select(\n",
    "            col(\"id\").alias(\"npc_id\"),\n",
    "            col(\"name\").alias(\"npc_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"location\").alias(\"location_text\"),\n",
    "            col(\"role\"),\n",
    "            col(\"voiced_by\"),\n",
    "            col(\"description\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} NPCs\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_creatures(self) -> DataFrame:\n",
    "        \"\"\"Transform creatures (table 6/28)\"\"\"\n",
    "        logger.info(\"Transforming creatures...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.creatures\")\n",
    "        \n",
    "        df_silver = df.select(\n",
    "            col(\"id\").alias(\"creature_id\"),\n",
    "            col(\"name\").alias(\"creature_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"locations\").alias(\"location_text\"),\n",
    "            col(\"drops\"),\n",
    "            col(\"blockquote\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} creatures\")\n",
    "        return df_silver\n",
    "\n",
    "\n",
    "    def transform_locations(self) -> DataFrame:\n",
    "        \"\"\"Transform locations (table 7/28)\"\"\"\n",
    "        logger.info(\"Transforming locations...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.locations\")\n",
    "        \n",
    "        df_silver = df.select(\n",
    "            col(\"id\").alias(\"location_id\"),\n",
    "            col(\"name\").alias(\"location_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"region\"),\n",
    "            col(\"items\"),\n",
    "            col(\"npcs\"),\n",
    "            col(\"creatures\"),\n",
    "            col(\"bosses\"),\n",
    "            col(\"description\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} locations\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_skills(self) -> DataFrame:\n",
    "        \"\"\"Transform skills (table 8/28)\"\"\"\n",
    "        logger.info(\"Transforming skills...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.skills\")\n",
    "\n",
    "        df_parsed =df \\\n",
    "            .withColumn(\"fp_parsed\", parse_fp_udf(col(\"fp\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"skill_id\"),\n",
    "            col(\"name\").alias(\"skill_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"type\"),\n",
    "            col(\"equipament\").alias(\"equipment\"),\n",
    "            col(\"charge\"),\n",
    "            col(\"fp_parsed.min\").alias(\"fp_cost_min\"),\n",
    "            col(\"fp_parsed.max\").alias(\"fp_cost_max\"),\n",
    "            col(\"fp_parsed.per_use\").alias(\"fp_cost_per_use\"),\n",
    "            col(\"fp_parsed.type\").alias(\"fp_cost_type\"),\n",
    "            col(\"effect\"),\n",
    "            col(\"locations\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} skills\")\n",
    "        return df_silver\n",
    "    \n",
    "\n",
    "    def transform_talismans(self) -> DataFrame:\n",
    "        \"\"\"Transform talismans (table 9/28)\"\"\"\n",
    "        logger.info(\"Transforming talismans...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.talismans\")\n",
    "        \n",
    "        df_silver = df.select(\n",
    "            col(\"id\").alias(\"talisman_id\"),\n",
    "            col(\"name\").alias(\"talisman_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"effect\"),\n",
    "            coalesce(col(\"weight\").cast(DoubleType()), lit(0.0)).alias(\"weight\"),\n",
    "            coalesce(expr(\"try_cast(value as int)\"),lit(0)).alias(\"value\"),   \n",
    "            col(\"description\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} talismans\")\n",
    "        return df_silver\n",
    "\n",
    "    def transform_sorceries(self) -> DataFrame:\n",
    "        \"\"\"Transform sorceries (table 10/28)\"\"\"\n",
    "        logger.info(\"Transforming sorceries...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.sorceries\")\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"fp_parsed\", parse_fp_udf(col(\"fp\")))\n",
    "           \n",
    "        \n",
    "        # Sorceries.csv has separate INT, FAI, ARC columns (not a dict)\n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"sorcery_id\"),\n",
    "            col(\"name\").alias(\"sorcery_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"description\"),\n",
    "            col(\"effect\"),\n",
    "            col(\"fp_parsed.min\").alias(\"fp_cost_min\"),\n",
    "            col(\"fp_parsed.max\").alias(\"fp_cost_max\"),\n",
    "            col(\"fp_parsed.per_use\").alias(\"fp_cost_per_use\"),\n",
    "            col(\"fp_parsed.type\").alias(\"fp_cost_type\"),\n",
    "            coalesce(col(\"slot\").cast(IntegerType()), lit(0)).alias(\"memory_slots\"),\n",
    "            coalesce(col(\"int\").cast(IntegerType()), lit(0)).alias(\"required_int\"),\n",
    "            coalesce(col(\"fai\").cast(IntegerType()), lit(0)).alias(\"required_fai\"),\n",
    "            coalesce(col(\"arc\").cast(IntegerType()), lit(0)).alias(\"required_arc\"),\n",
    "            coalesce(col(\"stamina_cost\").cast(IntegerType()), lit(0)).alias(\"stamina_cost\"),\n",
    "            col(\"bonus\"),\n",
    "            col(\"location\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} sorceries\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_incantations(self) -> DataFrame:\n",
    "        \"\"\"Transform incantations (table 11/28)\"\"\"\n",
    "        logger.info(\"Transforming incantations...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.incantations\")\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"fp_parsed\", parse_fp_udf(col(\"fp\")))\n",
    "        \n",
    "        # Incantations.csv has separate INT, FAI, ARC columns (not a dict)\n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"incantation_id\"),\n",
    "            col(\"name\").alias(\"incantation_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"description\"),\n",
    "            col(\"effect\"),\n",
    "            col(\"fp_parsed.min\").alias(\"fp_cost_min\"),\n",
    "            col(\"fp_parsed.max\").alias(\"fp_cost_max\"),\n",
    "            col(\"fp_parsed.per_use\").alias(\"fp_cost_per_use\"),\n",
    "            col(\"fp_parsed.type\").alias(\"fp_cost_type\"),\n",
    "            coalesce(col(\"slot\").cast(IntegerType()), lit(0)).alias(\"memory_slots\"),\n",
    "            coalesce(col(\"int\").cast(IntegerType()), lit(0)).alias(\"required_int\"),\n",
    "            coalesce(col(\"fai\").cast(IntegerType()), lit(0)).alias(\"required_fai\"),\n",
    "            coalesce(col(\"arc\").cast(IntegerType()), lit(0)).alias(\"required_arc\"),\n",
    "            coalesce(col(\"stamina_cost\").cast(IntegerType()), lit(0)).alias(\"stamina_cost\"),\n",
    "            col(\"bonus\"),\n",
    "            col(\"group\"),\n",
    "            col(\"location\"),\n",
    "            when(col(\"dlc\").isNull(), lit(0))\n",
    "            .when(lower(col(\"dlc\")).contains(\"base\"), lit(0))\n",
    "            .when(lower(col(\"dlc\")) == \"0\", lit(0))\n",
    "            .otherwise(lit(1))\n",
    "            .alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} incantations\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_ashes_of_war(self) -> DataFrame:\n",
    "        \"\"\"Transform ashes of war (table 12/28)\"\"\"\n",
    "        logger.info(\"Transforming ashes of war...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.ashes_of_war\")\n",
    "        \n",
    "        df_silver = df.select(\n",
    "            col(\"id\").alias(\"ash_id\"),\n",
    "            col(\"name\").alias(\"ash_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"affinity\"),\n",
    "            col(\"skill\"),\n",
    "            col(\"description\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} ashes of war\")\n",
    "        return df_silver\n",
    "\n",
    "    def transform_spirit_ashes(self) -> DataFrame:\n",
    "        \"\"\"Transform spirit ashes (table 13/28)\"\"\"\n",
    "        logger.info(\"Transforming spirit ashes...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.spirit_ashes\")\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"fp_parsed\", parse_fp_udf(col(\"fp_cost\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"spirit_id\"),\n",
    "            col(\"name\").alias(\"spirit_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"type\"),\n",
    "            col(\"fp_parsed.min\").alias(\"fp_cost_min\"),\n",
    "            col(\"fp_parsed.max\").alias(\"fp_cost_max\"),\n",
    "            col(\"fp_parsed.per_use\").alias(\"fp_cost_per_use\"),\n",
    "            col(\"fp_parsed.type\").alias(\"fp_cost_type\"),\n",
    "            coalesce(col(\"hp_cost\").cast(IntegerType()), lit(0)).alias(\"hp_cost\"),\n",
    "            col(\"effect\"),\n",
    "            col(\"description\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} spirit ashes\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_ammos(self) -> DataFrame:\n",
    "        \"\"\"Transform ammos with attack power parsing (table 16/28)\"\"\"\n",
    "        logger.info(\"Transforming ammos...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.items_ammos\")\n",
    "        \n",
    "        # Parse attack power\n",
    "        df_parsed = df.withColumn(\"attack_parsed\", parse_attack_udf(col(\"attack_power\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"ammo_id\"),\n",
    "            col(\"name\").alias(\"ammo_name\"),\n",
    "            col(\"image\"),\n",
    "            col(\"type\").alias(\"ammo_type\"),\n",
    "            col(\"damage_type\"),\n",
    "            # Attack stats with critical\n",
    "            coalesce(col(\"attack_parsed\")['physical'], lit(0)).alias(\"attack_physical\"),\n",
    "            coalesce(col(\"attack_parsed\")['magic'], lit(0)).alias(\"attack_magic\"),\n",
    "            coalesce(col(\"attack_parsed\")['fire'], lit(0)).alias(\"attack_fire\"),\n",
    "            coalesce(col(\"attack_parsed\")['lightning'], lit(0)).alias(\"attack_lightning\"),\n",
    "            coalesce(col(\"attack_parsed\")['holy'], lit(0)).alias(\"attack_holy\"),\n",
    "            coalesce(col(\"attack_parsed\")['critical'], lit(100)).alias(\"critical_damage\"),\n",
    "            col(\"passive_effect\"),\n",
    "            col(\"description\"),\n",
    "            coalesce(col(\"dlc\").cast(IntegerType()), lit(0)).alias(\"is_dlc\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} ammos\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_weapons_upgrades(self) -> DataFrame:\n",
    "        \"\"\"Transform weapon upgrades (table 14/28)\"\"\"\n",
    "        logger.info(\"Transforming weapon upgrades...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.weapons_upgrades\")\n",
    "        \n",
    "        # Parse attack and defense stats\n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"attack_parsed\", parse_attack_udf(col(\"attack_power\"))) \\\n",
    "            .withColumn(\"defense_parsed\", parse_defense_udf(col(\"damage_reduction_%\")))\\\n",
    "            .withColumn(\"scaling_parsed\", parse_scaling_udf(col(\"stat_scaling\")))\\\n",
    "            .withColumn(\"passive_effects_parsed\", parse_passive_effects_udf(col(\"passive_effects\")))\n",
    "        \n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"upgrade_id\"),\n",
    "            col(\"weapon_name\"),\n",
    "            col(\"upgrade\").alias(\"upgrade_level\"),\n",
    "            # Attack stats\n",
    "            coalesce(col(\"attack_parsed\")['physical'], lit(0)).alias(\"attack_physical\"),\n",
    "            coalesce(col(\"attack_parsed\")['magic'], lit(0)).alias(\"attack_magic\"),\n",
    "            coalesce(col(\"attack_parsed\")['fire'], lit(0)).alias(\"attack_fire\"),\n",
    "            coalesce(col(\"attack_parsed\")['lightning'], lit(0)).alias(\"attack_lightning\"),\n",
    "            coalesce(col(\"attack_parsed\")['holy'], lit(0)).alias(\"attack_holy\"),\n",
    "            coalesce(col(\"attack_parsed\")['stamina'], lit(0)).alias(\"stamina_cost\"),\n",
    "            coalesce(col(\"attack_parsed\")['critical'], lit(0)).alias(\"critical_damage\"),\n",
    "            # Scaling grades\n",
    "            coalesce(col(\"scaling_parsed\")['str'], lit('-')).alias(\"scaling_str\"),\n",
    "            coalesce(col(\"scaling_parsed\")['dex'], lit('-')).alias(\"scaling_dex\"),\n",
    "            coalesce(col(\"scaling_parsed\")['int'], lit('-')).alias(\"scaling_int\"),\n",
    "            coalesce(col(\"scaling_parsed\")['fai'], lit('-')).alias(\"scaling_fai\"),\n",
    "            coalesce(col(\"scaling_parsed\")['arc'], lit('-')).alias(\"scaling_arc\"),\n",
    "            # Guard/Defense stats (for weapons with shields like Dueling Shield)\n",
    "            coalesce(col(\"defense_parsed\")['physical'], lit(0.0)).alias(\"guard_physical\"),\n",
    "            coalesce(col(\"defense_parsed\")['magic'], lit(0.0)).alias(\"guard_magic\"),\n",
    "            coalesce(col(\"defense_parsed\")['fire'], lit(0.0)).alias(\"guard_fire\"),\n",
    "            coalesce(col(\"defense_parsed\")['lightning'], lit(0.0)).alias(\"guard_lightning\"),\n",
    "            coalesce(col(\"defense_parsed\")['holy'], lit(0.0)).alias(\"guard_holy\"),\n",
    "            coalesce(col(\"defense_parsed\")['boost'], lit(0.0)).alias(\"guard_boost\"),\n",
    "            coalesce(col(\"defense_parsed\")['resistance'], lit(0.0)).alias(\"guard_resistance\"),\n",
    "            # PASSIVE EFFECTS \n",
    "            col(\"passive_effects_parsed.effect_type\").alias(\"passive_effect_type\"),\n",
    "            col(\"passive_effects_parsed.buildup_primary\").alias(\"passive_buildup_primary\"),\n",
    "            col(\"passive_effects_parsed.buildup_secondary\").alias(\"passive_buildup_secondary\"),\n",
    "            col(\"passive_effects_parsed.has_dual_buildup\").alias(\"has_dual_buildup\"),\n",
    "            col(\"passive_effects_parsed.has_effect\").alias(\"has_passive_effect\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} weapon upgrades\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_shields_upgrades(self) -> DataFrame:\n",
    "        \"\"\"Transform shield upgrades (table 15/28)\"\"\"\n",
    "        logger.info(\"Transforming shield upgrades...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.shields_upgrades\")\n",
    "        \n",
    "        df_parsed = df \\\n",
    "            .withColumn(\"attack_parsed\", parse_attack_udf(col(\"attack_power\"))) \\\n",
    "            .withColumn(\"defense_parsed\", parse_defense_udf(col(\"damage_reduction_%\"))) \\\n",
    "            .withColumn(\"scaling_parsed\", parse_scaling_udf(col(\"stat_scaling\")))\\\n",
    "            .withColumn(\"passive_effects_parsed\", parse_passive_effects_udf(col(\"passive_effects\")))\n",
    "\n",
    "        df_silver = df_parsed.select(\n",
    "            col(\"id\").alias(\"upgrade_id\"),\n",
    "            col(\"shield_name\").alias(\"shield_name\"),\n",
    "            col(\"upgrade\").alias(\"upgrade_level\"),\n",
    "            # Attack stats (shield bash damage)\n",
    "            coalesce(col(\"attack_parsed\")['physical'], lit(0)).alias(\"attack_physical\"),\n",
    "            coalesce(col(\"attack_parsed\")['magic'], lit(0)).alias(\"attack_magic\"),\n",
    "            coalesce(col(\"attack_parsed\")['fire'], lit(0)).alias(\"attack_fire\"),\n",
    "            coalesce(col(\"attack_parsed\")['lightning'], lit(0)).alias(\"attack_lightning\"),\n",
    "            coalesce(col(\"attack_parsed\")['holy'], lit(0)).alias(\"attack_holy\"),\n",
    "            coalesce(col(\"attack_parsed\")['stamina'], lit(0)).alias(\"stamina_cost\"),\n",
    "            # Guard stats (primary shield function)\n",
    "            coalesce(col(\"defense_parsed\")['physical'], lit(0.0)).alias(\"guard_physical\"),\n",
    "            coalesce(col(\"defense_parsed\")['magic'], lit(0.0)).alias(\"guard_magic\"),\n",
    "            coalesce(col(\"defense_parsed\")['fire'], lit(0.0)).alias(\"guard_fire\"),\n",
    "            coalesce(col(\"defense_parsed\")['lightning'], lit(0.0)).alias(\"guard_lightning\"),\n",
    "            coalesce(col(\"defense_parsed\")['holy'], lit(0.0)).alias(\"guard_holy\"),\n",
    "            coalesce(col(\"defense_parsed\")['boost'], lit(0.0)).alias(\"guard_boost\"),\n",
    "            coalesce(col(\"defense_parsed\")['resistance'], lit(0.0)).alias(\"guard_resistance\"),\n",
    "            # Scaling grades\n",
    "            coalesce(col(\"scaling_parsed\")['str'], lit('-')).alias(\"scaling_str\"),\n",
    "            coalesce(col(\"scaling_parsed\")['dex'], lit('-')).alias(\"scaling_dex\"),\n",
    "            coalesce(col(\"scaling_parsed\")['int'], lit('-')).alias(\"scaling_int\"),\n",
    "            coalesce(col(\"scaling_parsed\")['fai'], lit('-')).alias(\"scaling_fai\"),\n",
    "            coalesce(col(\"scaling_parsed\")['arc'], lit('-')).alias(\"scaling_arc\"),\n",
    "            # PASSIVE EFFECTS (UPDATED - handles dual buildup)\n",
    "            col(\"passive_effects_parsed.effect_type\").alias(\"passive_effect_type\"),\n",
    "            col(\"passive_effects_parsed.buildup_primary\").alias(\"passive_buildup_primary\"),\n",
    "            col(\"passive_effects_parsed.buildup_secondary\").alias(\"passive_buildup_secondary\"),\n",
    "            col(\"passive_effects_parsed.has_dual_buildup\").alias(\"has_dual_buildup\"),\n",
    "            col(\"passive_effects_parsed.has_effect\").alias(\"has_passive_effect\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} shield upgrades\")\n",
    "        return df_silver\n",
    "    \n",
    "    def transform_item_table(self, table_suffix: str, item_type: str) -> DataFrame:\n",
    "        \"\"\"Generic transform for item tables (tables 16-28)\"\"\"\n",
    "        logger.info(f\"Transforming {table_suffix}...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.bronze_schema}.{table_suffix}\")\n",
    "        \n",
    "        available_cols = df.columns\n",
    "        \n",
    "        select_cols = [\n",
    "            col(\"id\").alias(\"item_id\"),\n",
    "            col(\"name\").alias(\"item_name\"),\n",
    "            lit(item_type).alias(\"item_type\")\n",
    "        ]\n",
    "        \n",
    "        if \"description\" in available_cols:\n",
    "            select_cols.append(col(\"description\"))\n",
    "        else:\n",
    "            select_cols.append(lit(None).cast(StringType()).alias(\"description\"))\n",
    "        \n",
    "        if \"effect\" in available_cols:\n",
    "            select_cols.append(col(\"effect\"))\n",
    "        else:\n",
    "            select_cols.append(lit(None).cast(StringType()).alias(\"effect\"))\n",
    "        \n",
    "        if \"image\" in available_cols:\n",
    "            select_cols.append(col(\"image\"))\n",
    "        else:\n",
    "            select_cols.append(lit(None).cast(StringType()).alias(\"image\"))\n",
    "        \n",
    "        select_cols.extend([\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            current_timestamp().alias(\"silver_timestamp\")\n",
    "        ])\n",
    "        \n",
    "        df_silver = df.select(*select_cols)\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_silver.count():,} {item_type}s\")\n",
    "        return df_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e605a360-ca51-4f75-a70a-4f7a5d398563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ArrayExploder:\n",
    "    \"\"\"Handles array explosions\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.catalog = config[\"catalog\"]\n",
    "        self.silver_schema = config[\"silver_schema\"]\n",
    "    \n",
    "    def explode_location_items(self) -> DataFrame:\n",
    "        \"\"\"Explode location items\"\"\"\n",
    "        logger.info(\"Exploding location items...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.silver_schema}.locations\")\n",
    "        \n",
    "        df_exploded = df \\\n",
    "            .filter(col(\"items\").isNotNull()) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                col(\"location_name\"),\n",
    "                split(regexp_replace(col(\"items\"), r\"[\\[\\]'\\\"]\", \"\"), \",\\\\s*\").alias(\"items_array\")\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                explode(col(\"items_array\")).alias(\"item_name\")\n",
    "            ) \\\n",
    "            .filter(col(\"item_name\") != \"\")\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_exploded.count():,} relationships\")\n",
    "        return df_exploded\n",
    "    \n",
    "    def explode_location_npcs(self) -> DataFrame:\n",
    "        \"\"\"Explode location NPCs\"\"\"\n",
    "        logger.info(\"Exploding location NPCs...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.silver_schema}.locations\")\n",
    "        \n",
    "        df_exploded = df \\\n",
    "            .filter(col(\"npcs\").isNotNull()) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                split(regexp_replace(col(\"npcs\"), r\"[\\[\\]'\\\"]\", \"\"), \",\\\\s*\").alias(\"npcs_array\")\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                explode(col(\"npcs_array\")).alias(\"npc_name\")\n",
    "            ) \\\n",
    "            .filter(col(\"npc_name\") != \"\")\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_exploded.count():,} relationships\")\n",
    "        return df_exploded\n",
    "    \n",
    "    def explode_location_creatures(self) -> DataFrame:\n",
    "        \"\"\"Explode location creatures\"\"\"\n",
    "        logger.info(\"Exploding location creatures...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.silver_schema}.locations\")\n",
    "        \n",
    "        df_exploded = df \\\n",
    "            .filter(col(\"creatures\").isNotNull()) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                split(regexp_replace(col(\"creatures\"), r\"[\\[\\]'\\\"]\", \"\"), \",\\\\s*\").alias(\"creatures_array\")\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                explode(col(\"creatures_array\")).alias(\"creature_name\")\n",
    "            ) \\\n",
    "            .filter(col(\"creature_name\") != \"\")\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_exploded.count():,} relationships\")\n",
    "        return df_exploded\n",
    "    \n",
    "    def explode_location_bosses(self) -> DataFrame:\n",
    "        \"\"\"Explode location bosses\"\"\"\n",
    "        logger.info(\"Exploding location bosses...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.silver_schema}.locations\")\n",
    "        \n",
    "        df_exploded = df \\\n",
    "            .filter(col(\"bosses\").isNotNull()) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                split(regexp_replace(col(\"bosses\"), r\"[\\[\\]'\\\"]\", \"\"), \",\\\\s*\").alias(\"bosses_array\")\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"location_id\"),\n",
    "                explode(col(\"bosses_array\")).alias(\"boss_name\")\n",
    "            ) \\\n",
    "            .filter(col(\"boss_name\") != \"\")\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_exploded.count():,} relationships\")\n",
    "        return df_exploded\n",
    "    \n",
    "    def explode_boss_drops(self) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Explode boss drops from locations_and_drops column\n",
    "        \n",
    "        Handles complex nested dict format with multiple locations:\n",
    "        {'Location1': ['drop1', 'drop2'], 'Location2': ['drop3', 'drop4']}\n",
    "        \n",
    "        Also handles HTML anchor tags in location names and comma-formatted numbers\n",
    "        \n",
    "        Classifies drops into:\n",
    "        - 'runes': Numeric values or text containing 'Runes'\n",
    "        - 'remembrance': Items containing 'Remembrance'\n",
    "        - 'great_rune': Great Runes\n",
    "        - 'weapon': Weapon-related drops\n",
    "        - 'armor': Armor-related drops\n",
    "        - 'material': Crafting/upgrade materials\n",
    "        - 'item': Everything else\n",
    "        \"\"\"\n",
    "        logger.info(\"Exploding boss drops...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.silver_schema}.bosses\")\n",
    "        \n",
    "        # Step 1: Parse the dict-like string structure\n",
    "        df_processed = df \\\n",
    "            .filter(col(\"locations_and_drops\").isNotNull()) \\\n",
    "            .filter(col(\"locations_and_drops\") != \"\") \\\n",
    "            .select(\n",
    "                col(\"boss_id\"),\n",
    "                col(\"boss_name\"),\n",
    "                # Remove outer braces\n",
    "                regexp_replace(col(\"locations_and_drops\"), r\"^\\{|\\}$\", \"\").alias(\"locations_text\")\n",
    "            )\n",
    "        \n",
    "        # Step 2: Split by location patterns (look for ': [' to identify new locations)\n",
    "        df_split = df_processed \\\n",
    "            .withColumn(\n",
    "                \"location_entries\",\n",
    "                split(col(\"locations_text\"), r\"(?=(?:'[^']*'|\\\"[^\\\"]*\\\"|<a[^>]*>[^<]*</a>):\\s*\\[)\")\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"boss_id\"),\n",
    "                col(\"boss_name\"),\n",
    "                explode(col(\"location_entries\")).alias(\"location_entry\")\n",
    "            ) \\\n",
    "            .filter(col(\"location_entry\") != \"\")\n",
    "        \n",
    "        # Step 3: Extract location name and drops array\n",
    "        df_extracted = df_split \\\n",
    "            .withColumn(\n",
    "                \"location_raw\",\n",
    "                regexp_extract(col(\"location_entry\"), r\"^([^:]+):\\s*\\[\", 1)\n",
    "            ) \\\n",
    "            .withColumn(\n",
    "                \"drops_text\",\n",
    "                regexp_extract(col(\"location_entry\"), r\":\\s*\\[([^\\]]+)\\]\", 1)\n",
    "            ) \\\n",
    "            .filter(col(\"location_raw\") != \"\") \\\n",
    "            .filter(col(\"drops_text\") != \"\")\n",
    "        \n",
    "        # Step 4: Clean location names (remove HTML tags, quotes, extra spaces)\n",
    "        df_cleaned_location = df_extracted \\\n",
    "            .withColumn(\n",
    "                \"location_name\",\n",
    "                trim(\n",
    "                    regexp_replace(\n",
    "                        regexp_replace(\n",
    "                            regexp_replace(col(\"location_raw\"), r\"<a[^>]*>([^<]*)</a>\", \"$1\"),\n",
    "                            r\"['\\\"]+\", \"\"\n",
    "                        ),\n",
    "                        r\"\\s+\", \" \"\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Step 5: Split drops array - USE LOOKAHEAD TO AVOID SPLITTING COMMA-FORMATTED NUMBERS\n",
    "        # Split on: ', ' followed by a quote OR comma-space ONLY if not between digits\n",
    "        df_exploded = df_cleaned_location \\\n",
    "            .withColumn(\n",
    "                \"drops_array\",\n",
    "                # Remove quotes first, then split on pattern that preserves comma-formatted numbers\n",
    "                split(\n",
    "                    regexp_replace(col(\"drops_text\"), r\"['\\\"]+\", \"\"),\n",
    "                    r\",\\s*(?=\\D)\"  # Split on comma-space ONLY if followed by non-digit\n",
    "                )\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"boss_id\"),\n",
    "                col(\"boss_name\"),\n",
    "                col(\"location_name\"),\n",
    "                explode(col(\"drops_array\")).alias(\"drop_item\")\n",
    "            ) \\\n",
    "            .withColumn(\"drop_item\", trim(col(\"drop_item\"))) \\\n",
    "            .filter(col(\"drop_item\") != \"\") \\\n",
    "            .filter(~col(\"drop_item\").contains(\":\"))  # Filter out any remaining location fragments\n",
    "        \n",
    "        # Step 6: Classify drop types\n",
    "        df_typed = df_exploded.withColumn(\n",
    "            \"drop_type\",\n",
    "            when(\n",
    "                # RUNES: Contains 'Rune' (case-insensitive) OR is comma-formatted number\n",
    "                (lower(col(\"drop_item\")).contains(\"rune\")) |\n",
    "                (col(\"drop_item\").rlike(r\"^\\d{1,3}(,\\d{3})*$\")),  # Matches: 240,000 or 90,000\n",
    "                lit(\"runes\")\n",
    "            )\n",
    "            .when(\n",
    "                # REMEMBRANCE: Contains \"Remembrance\"\n",
    "                lower(col(\"drop_item\")).contains(\"remembrance\"),\n",
    "                lit(\"remembrance\")\n",
    "            )\n",
    "            .when(\n",
    "                # GREAT RUNE: Contains \"Great Rune\"\n",
    "                lower(col(\"drop_item\")).contains(\"great rune\"),\n",
    "                lit(\"great_rune\")\n",
    "            )\n",
    "            .when(\n",
    "                # DRAGON HEART: Special material\n",
    "                lower(col(\"drop_item\")).contains(\"dragon heart\"),\n",
    "                lit(\"material\")\n",
    "            )\n",
    "            .when(\n",
    "                # WEAPON: Common weapon keywords\n",
    "                (lower(col(\"drop_item\")).contains(\"sword\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"blade\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"axe\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"spear\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"katana\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"bow\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"staff\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"halberd\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"hammer\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"flail\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"seal\")),\n",
    "                lit(\"weapon\")\n",
    "            )\n",
    "            .when(\n",
    "                # ARMOR: Common armor keywords\n",
    "                (lower(col(\"drop_item\")).contains(\"armor\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"helm\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"gauntlet\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"greaves\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"chest\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"hood\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"mask\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"set\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"cloak\")),\n",
    "                lit(\"armor\")\n",
    "            )\n",
    "            .when(\n",
    "                # MATERIAL: Crafting/upgrade materials\n",
    "                (lower(col(\"drop_item\")).contains(\"flesh\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"scale\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"bone\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"smithing stone\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"glovewort\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"somber\")),\n",
    "                lit(\"material\")\n",
    "            )\n",
    "            .when(\n",
    "                # TALISMAN: Talismans/medallions/charms\n",
    "                (lower(col(\"drop_item\")).contains(\"talisman\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"medallion\")) |\n",
    "                (lower(col(\"drop_item\")).contains(\"charm\")),\n",
    "                lit(\"talisman\")\n",
    "            )\n",
    "            .when(\n",
    "                # ASH OF WAR\n",
    "                lower(col(\"drop_item\")).contains(\"ash of war\"),\n",
    "                lit(\"ash_of_war\")\n",
    "            )\n",
    "            .otherwise(lit(\"item\"))  # Default: generic item\n",
    "        )\n",
    "        \n",
    "        # Step 7: Add drop order within each boss-location combination\n",
    "        df_final = df_typed.withColumn(\n",
    "            \"drop_order\",\n",
    "            row_number().over(\n",
    "                Window.partitionBy(\"boss_id\", \"location_name\")\n",
    "                .orderBy(monotonically_increasing_id())\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_final.count():,} boss drop relationships\")\n",
    "        \n",
    "        # Log distribution by drop type\n",
    "        logger.info(\"\\n  \uD83D\uDCCA Drop Type Distribution:\")\n",
    "        type_counts = df_final.groupBy(\"drop_type\").count().orderBy(col(\"count\").desc()).collect()\n",
    "        for row in type_counts:\n",
    "            logger.info(f\"     • {row['drop_type']:<15}: {row['count']:>6,} drops\")\n",
    "        \n",
    "        return df_final\n",
    "    \n",
    "    def explode_creature_drops(self) -> DataFrame:\n",
    "        \"\"\"Explode creature drops\"\"\"\n",
    "        logger.info(\"Exploding creature drops...\")\n",
    "        \n",
    "        df = spark.table(f\"{self.catalog}.{self.silver_schema}.creatures\")\n",
    "        \n",
    "        df_exploded = df \\\n",
    "            .filter(col(\"drops\").isNotNull()) \\\n",
    "            .select(\n",
    "                col(\"creature_id\"),\n",
    "                col(\"creature_name\"),\n",
    "                split(regexp_replace(col(\"drops\"), r\"[\\[\\]'\\\"]\", \"\"), \",\\\\s*\").alias(\"drops_array\")\n",
    "            ) \\\n",
    "            .select(\n",
    "                col(\"creature_id\"),\n",
    "                col(\"creature_name\"),\n",
    "                explode(col(\"drops_array\")).alias(\"item_name\")\n",
    "            ) \\\n",
    "            .filter(col(\"item_name\") != \"\")\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_exploded.count():,} relationships\")\n",
    "        return df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40d8e733-2c08-4a1e-bb70-69ef6072f2ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_unified_items_table(config: Dict) -> DataFrame:\n",
    "    \"\"\"Create unified items lookup (13 item types)\"\"\"\n",
    "    logger.info(\"Creating unified items table...\")\n",
    "    \n",
    "    item_configs = [\n",
    "        (\"items_ammos\", \"Ammo\"),\n",
    "        (\"items_bells\", \"Bell\"),\n",
    "        (\"items_consumables\", \"Consumable\"),\n",
    "        (\"items_cookbooks\", \"Cookbook\"),\n",
    "        (\"items_crystal_tears\", \"Crystal Tear\"),\n",
    "        (\"items_great_runes\", \"Great Rune\"),\n",
    "        (\"items_key_items\", \"Key Item\"),\n",
    "        (\"items_materials\", \"Material\"),\n",
    "        (\"items_multi\", \"Multi\"),\n",
    "        (\"items_remembrances\", \"Remembrance\"),\n",
    "        (\"items_tools\", \"Tool\"),\n",
    "        (\"items_upgrade_materials\", \"Upgrade Material\"),\n",
    "        (\"items_whetblades\", \"Whetblade\")\n",
    "    ]\n",
    "    \n",
    "    transformer = SilverTransformer(config)\n",
    "    dfs = []\n",
    "    \n",
    "    for table_suffix, item_type in item_configs:\n",
    "        try:\n",
    "            df = transformer.transform_item_table(table_suffix, item_type)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load {table_suffix}: {e}\")\n",
    "    \n",
    "    if dfs:\n",
    "        df_unified = dfs[0]\n",
    "        for df in dfs[1:]:\n",
    "            df_unified = df_unified.unionByName(df, allowMissingColumns=True)\n",
    "        \n",
    "        logger.info(f\"  ✅ {df_unified.count():,} total items\")\n",
    "        return df_unified\n",
    "    else:\n",
    "        return spark.createDataFrame([], StructType([\n",
    "            StructField(\"item_id\", StringType()),\n",
    "            StructField(\"item_name\", StringType()),\n",
    "            StructField(\"item_type\", StringType()),\n",
    "            StructField(\"description\", StringType()),\n",
    "            StructField(\"effect\", StringType()),\n",
    "            StructField(\"image\", StringType())\n",
    "        ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bacdc95-e008-4d59-a544-e1a95c569d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_silver_transformations(config: Dict) -> Dict:\n",
    "    \"\"\"Main orchestration for ALL 28 tables\"\"\"\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"STARTING SILVER LAYER - ALL 28 TABLES\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    transformer = SilverTransformer(config)\n",
    "    exploder = ArrayExploder(config)\n",
    "    \n",
    "    stats = {\"start_time\": datetime.now(), \"tables_created\": []}\n",
    "    \n",
    "    # Create schema\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {config['catalog']}.{config['silver_schema']}\")\n",
    "    \n",
    "    # PHASE 1: Base tables (16 main entities including ammos)\n",
    "    logger.info(\"\\n\uD83D\uDCE6 PHASE 1: Base transformations (16 main entities)\")\n",
    "    \n",
    "    base_tables = [\n",
    "        (\"weapons\", transformer.transform_weapons),\n",
    "        (\"shields\", transformer.transform_shields),\n",
    "        (\"armors\", transformer.transform_armors),\n",
    "        (\"bosses\", transformer.transform_bosses),\n",
    "        (\"npcs\", transformer.transform_npcs),\n",
    "        (\"creatures\", transformer.transform_creatures),\n",
    "        (\"locations\", transformer.transform_locations),\n",
    "        (\"skills\", transformer.transform_skills),\n",
    "        (\"talismans\", transformer.transform_talismans),\n",
    "        (\"sorceries\", transformer.transform_sorceries),\n",
    "        (\"incantations\", transformer.transform_incantations),\n",
    "        (\"ashes_of_war\", transformer.transform_ashes_of_war),\n",
    "        (\"spirit_ashes\", transformer.transform_spirit_ashes),\n",
    "        (\"items_ammos\", transformer.transform_ammos),\n",
    "        (\"weapons_upgrades\", transformer.transform_weapons_upgrades),\n",
    "        (\"shields_upgrades\", transformer.transform_shields_upgrades)\n",
    "    ]\n",
    "    \n",
    "    for table_name, transform_func in base_tables:\n",
    "        try:\n",
    "            df = transform_func()\n",
    "            full_table_name = f\"{config['catalog']}.{config['silver_schema']}.{table_name}\"\n",
    "            \n",
    "            df.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .saveAsTable(full_table_name)\n",
    "            \n",
    "            stats[\"tables_created\"].append(full_table_name)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"  ❌ Failed {table_name}: {e}\")\n",
    "    \n",
    "    # PHASE 2: Array explosions (6 tables)\n",
    "    logger.info(\"\\n\uD83D\uDCE6 PHASE 2: Array explosions\")\n",
    "    \n",
    "    explosion_tables = [\n",
    "        (\"location_items\", exploder.explode_location_items),\n",
    "        (\"location_npcs\", exploder.explode_location_npcs),\n",
    "        (\"location_creatures\", exploder.explode_location_creatures),\n",
    "        (\"location_bosses\", exploder.explode_location_bosses),\n",
    "        (\"boss_drops\", exploder.explode_boss_drops),\n",
    "        (\"creature_drops\", exploder.explode_creature_drops)\n",
    "    ]\n",
    "    \n",
    "    for table_name, explode_func in explosion_tables:\n",
    "        try:\n",
    "            df = explode_func()\n",
    "            full_table_name = f\"{config['catalog']}.{config['silver_schema']}.{table_name}\"\n",
    "            \n",
    "            df.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .saveAsTable(full_table_name)\n",
    "            \n",
    "            stats[\"tables_created\"].append(full_table_name)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"  ❌ Failed {table_name}: {e}\")\n",
    "    \n",
    "    # PHASE 3: Unified items (1 table from 13 types)\n",
    "    logger.info(\"\\n\uD83D\uDCE6 PHASE 3: Unified items\")\n",
    "    \n",
    "    try:\n",
    "        df_items = create_unified_items_table(config)\n",
    "        full_table_name = f\"{config['catalog']}.{config['silver_schema']}.items_unified\"\n",
    "        \n",
    "        df_items.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .saveAsTable(full_table_name)\n",
    "        \n",
    "        stats[\"tables_created\"].append(full_table_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"  ❌ Failed items_unified: {e}\")\n",
    "    \n",
    "    stats[\"end_time\"] = datetime.now()\n",
    "    stats[\"duration\"] = (stats[\"end_time\"] - stats[\"start_time\"]).total_seconds()\n",
    "    \n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"✅ SILVER LAYER COMPLETE\")\n",
    "    logger.info(f\"Tables: {len(stats['tables_created'])}\")\n",
    "    logger.info(f\"Duration: {stats['duration']:.2f}s\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2578248-079b-4338-9ee6-444a7a354a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    CONFIG = {\n",
    "        \"catalog\": \"eldenringcatalog\",\n",
    "        \"bronze_schema\": \"bronze\",\n",
    "        \"silver_schema\": \"silver\",\n",
    "        \"batch_id\": datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        stats = run_silver_transformations(CONFIG)\n",
    "        \n",
    "        logger.info(\"\\n\uD83D\uDCCA SUMMARY\")\n",
    "        logger.info(f\"Total tables: {len(stats['tables_created'])}\")\n",
    "        for table in stats['tables_created']:\n",
    "            logger.info(f\"  • {table}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"\\n❌ Failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b14e3a7b-7fae-4bd3-9977-c4cfd646d5fe",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764087521993}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select* from eldenringcatalog.silver.location_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e002bce-a4fc-4c17-9e00-1291fff6379d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5947531305675768,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SILVER_LAYER",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}