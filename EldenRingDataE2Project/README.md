# Elden Ring Data End-to-End Project (> **Status:** ğŸš§ Work in Progress)

![Elden Ring](https://jeuxpourtous.org/wp-content/uploads/2022/09/Le-jeu-de-societe-Elden-Ring-est-officiellement-annonce.jpg)

**Playing Elden Ring with Data - A Different Way to Experience the Lands Between**

An end-to-end data engineering project that processes, cleans, and analyzes Elden Ring game data through a multi-layered architecture (Bronze, Silver, Gold) using PySpark on Databricks Free Edition. This project answers complex questions about the game through data analysis, revealing patterns and insights that enhance your gaming experience.

## ğŸ“‹ Project Overview

This project implements a comprehensive data pipeline for Elden Ring game data, covering 28 CSV files with information about weapons, armor, bosses, NPCs, locations, spells, items, and more. The pipeline follows the **medallion architecture** (Bronze-Silver-Gold layers) to transform raw data into analysis-ready datasets.

### ğŸ® Mission

**Experience Elden Ring through data.** Instead of just playing the game, explore it analytically - discover optimal builds, uncover hidden patterns, compare equipment effectiveness, and answer complex questions that would take hundreds of hours of gameplay to solve manually.

### ğŸ¯ Learning Objectives

This is a **practical data engineering project** demonstrating real-world skills:
- **Data Loading**: Initial batch loading and incremental loading strategies
- **Data Transformation**: Complex data cleaning and standardization
- **Data Modeling**: Dimensional modeling for analytics (Star Schema)
- **Data Quality**: Handling messy real-world data issues
- **Data Analysis**: SQL and PySpark analytics on large datasets
- **Data Visualization**: Dashboard creation for insights
- **ETL Orchestration**: End-to-end pipeline implementation on Databricks

### Key Features

- **Multi-layered Architecture**: Bronze (raw ingestion) â†’ Silver (cleansed & conformed) â†’ Gold (aggregated & analytics-ready)
- **Incremental Loading**: Support for both batch and incremental data loading patterns
- **Data Quality Management**: Handles complex data quality issues including dictionary strings, nested structures, and inconsistent null representations
- **Comprehensive Coverage**: 28 CSV files covering all major Elden Ring game entities
- **Databricks Implementation**: Built on Databricks Community Edition (Free Tier)
- **PySpark Processing**: Scalable data transformations using Apache Spark
- **Analytics & Dashboards**: Pre-built queries, dimensional models, and interactive visualizations

## ğŸ—‚ï¸ Project Structure

```
EldenRingDataE2Project/
â”œâ”€â”€ Data/                          # Raw CSV data files (28 files)
â”‚   â”œâ”€â”€ armors.csv
â”‚   â”œâ”€â”€ ashesOfWar.csv
â”‚   â”œâ”€â”€ bosses.csv
â”‚   â”œâ”€â”€ creatures.csv
â”‚   â”œâ”€â”€ incantations.csv
â”‚   â”œâ”€â”€ locations.csv
â”‚   â”œâ”€â”€ npcs.csv
â”‚   â”œâ”€â”€ shields.csv
â”‚   â”œâ”€â”€ shields_upgrades.csv
â”‚   â”œâ”€â”€ skills.csv
â”‚   â”œâ”€â”€ sorceries.csv
â”‚   â”œâ”€â”€ spiritAshes.csv
â”‚   â”œâ”€â”€ talismans.csv
â”‚   â”œâ”€â”€ weapons.csv
â”‚   â”œâ”€â”€ weapons_upgrades.csv
â”‚   â””â”€â”€ items/                     # Item subcategory files
â”‚       â”œâ”€â”€ ammos.csv
â”‚       â”œâ”€â”€ bells.csv
â”‚       â”œâ”€â”€ consumables.csv
â”‚       â”œâ”€â”€ cookbooks.csv
â”‚       â”œâ”€â”€ crystalTears.csv
â”‚       â”œâ”€â”€ greatRunes.csv
â”‚       â”œâ”€â”€ keyItems.csv
â”‚       â”œâ”€â”€ materials.csv
â”‚       â”œâ”€â”€ multi.csv
â”‚       â”œâ”€â”€ remembrances.csv
â”‚       â”œâ”€â”€ tools.csv
â”‚       â”œâ”€â”€ upgradeMaterials.csv
â”‚       â””â”€â”€ whetblades.csv
â”œâ”€â”€ Notebooks/                     # Jupyter notebooks for each layer
â”‚   â”œâ”€â”€ BRONZE_LAYER.ipynb        # Raw data ingestion
â”‚   â”œâ”€â”€ SILVER_LAYER.ipynb        # Data cleansing & transformation
â”‚   â”œâ”€â”€ GOLD_LAYER.ipynb          # Dimensional modeling & aggregations
â”‚   â””â”€â”€ ANALYTICS QUERIES.ipynb   # Analysis and insights
â””â”€â”€ docs/                          # Documentation
    â”œâ”€â”€ DATA SOURCES AND STRUCTURE.md
    â””â”€â”€ DATA QUALITY ISSUES (INITIAL ANALYSIS USING EXCEL).md
```

## ğŸ“Š Data Sources

**Total: 28 CSV files** (15 main entities + 13 item categories)

### Current Data Source
- **Kaggle Dataset**: [Elden Ring Ultimate Dataset](https://www.kaggle.com/datasets/robikscube/elden-ring-ultimate-dataset)
- **Completeness**: Working with available data; completeness status being evaluated

### Future Enhancement Plans
- **Web Scraping**: Plan to scrape [Elden Ring Wiki (fextralife)](https://eldenring.wiki.fextralife.com/) to:
  - Validate and complete existing data
  - Add missing items and attributes
  - Update with latest game patches and DLC content
  - Cross-reference and improve data quality

### Main Entities (15 core files)
- **Weapons** 
- **Shields** 
- **Armors** 
- **Bosses** 
- **Creatures** 
- **Locations** 
- **NPCs** 
- **Sorceries** 
- **Incantations** 
- **Talismans** 
- **Skills** 
- **Spirit Ashes** 
- **Ashes of War** 

### Item Categories (13 files)
Ammos, Bells, Consumables, Cookbooks, Crystal Tears, Great Runes, Key Items, Materials, Multi-use Items, Remembrances, Tools, Upgrade Materials, Whetblades

## ğŸ—ï¸ Architecture

### Bronze Layer (Raw Data Ingestion)
- **Purpose**: Load raw CSV files with minimal transformation
- **Processing**: Schema inference, basic type casting, metadata addition
- **Output**: Parquet files preserving source data structure

### Silver Layer (Cleansed & Conformed)
- **Purpose**: Clean and standardize data for consistency
- **Key Transformations**:
  - Parse dictionary strings (`{'Str': 15, 'Dex': 14}`)
  - Standardize null representations (`'-'`, `'N/A'`, `''` â†’ `NULL`)
  - Parse list strings and nested structures
  - Clean number formatting (remove commas)
  - Extract complex multi-phase values (e.g., boss HP phases)
- **Output**: Cleaned, typed, and normalized Parquet files

### Gold Layer (Analytics & Dimensional Models)
- **Purpose**: Create business-ready dimensional models and aggregations
- **Key Outputs**:
  - Dimensional models (facts and dimensions)
  - Aggregated statistics
  - Relationship tables (weapon-skill, armor-location, etc.)
  - Pre-computed analytics tables
- **Output**: Optimized Parquet files for analysis

## ğŸ”§ Technologies Used

- **Databricks Community Edition**: Cloud-based data engineering platform (Free Tier)
- **PySpark**: Distributed data processing framework
- **Python 3.x**: Primary programming language
- **Notebooks**: Interactive development and documentation
- **Apache Parquet**: Columnar storage format
- **Delta Lake**: Data lake storage (via Databricks)

## ğŸš€ Getting Started

### Prerequisites

- **Databricks Account**: Sign up for free at [Databricks Community Edition](https://community.cloud.databricks.com/)
- **Python 3.8+**: For local development (optional)

### Setup

1. **Create a Databricks workspace** (Community Edition)
2. **Upload the project files** to Databricks File System (DBFS)
3. **Import notebooks** to your Databricks workspace
4. **Create a cluster** (free tier allows up to 15GB memory)
5. **Run notebooks** in the following order:
   - BRONZE_LAYER.ipynb
   - SILVER_LAYER.ipynb
   - GOLD_LAYER.ipynb
   - ANALYTICS QUERIES.ipynb (IN PROGRESS)

### Running the Pipeline on Databricks

1. **BRONZE_LAYER.ipynb**: Ingest raw CSV data into Delta tables
2. **SILVER_LAYER.ipynb**: Clean and transform data with PySpark
3. **GOLD_LAYER.ipynb**: Create dimensional models and aggregations
4. **ANALYTICS QUERIES.ipynb**: Run analysis queries and prepare for dashboards

## ğŸ“ Data Quality Issues & Solutions

| Issue | Description | Solution |
|-------|-------------|----------|
| **Dictionary Strings** | Dictionaries stored as strings | Parse using `ast.literal_eval()` |
| **Null Representations** | Multiple null formats (`'-'`, `'N/A'`, `''`) | Standardize to SQL `NULL` |
| **List Strings** | Lists stored as strings | Parse and explode into rows |
| **Number Formatting** | Numbers with commas (`'6,080'`) | Remove commas, cast to integer |
| **Nested Structures** | Lists of dictionaries | Multi-stage parsing |
| **Complex HP Values** | Multi-phase boss HP | Regex extraction by phase |

## ğŸ“ˆ Analytics Capabilities

### Complex Questions Answered Through Data

**Build Optimization:**
- What's the most efficient strength build path from level 1 to 150?
- Which weapon has the highest damage-to-weight ratio for dexterity builds?
- What's the optimal armor combination for maximum defense with medium roll?

**Boss Strategy:**
- Which bosses drop the most valuable items per difficulty level?
- What's the statistical correlation between boss HP and rune rewards?
- Which Spirit Ashes are most effective against specific boss types?

**Resource Efficiency:**
- What's the most efficient smithing stone path to +25 weapons?
- Which locations have the highest density of upgrade materials?
- What's the ROI of different remembrance exchange options?

**Game Progression:**
- What's the optimal location progression for item collection?
- Which incantations/sorceries provide the best FP-to-damage ratio?
- How do DLC items compare to base game items statistically?

### Dashboards (In Progress)
- Interactive visualizations for game statistics
- Equipment comparison and recommendation engine
- Location and boss analytics
- Character build optimization tools
- Resource efficiency calculators

## ğŸ¯ Current Status

**Phase 1: Foundation (Completed)**
- âœ… Data sources documented (28 CSV files from Kaggle)
- âœ… Data quality issues identified and documented
- âœ… Bronze layer: Batch data loading to Delta tables
- âœ… Silver layer: Data cleaning & transformation logic
- âœ… Gold layer: Dimensional modeling (Star Schema)
- âœ… Databricks Community Edition setup and configuration
- âœ… Core analytics queries implementation

**Phase 2: In Progress**
- ğŸš§ Advanced analytics queries and complex aggregations
- ğŸš§ Interactive dashboards and visualizations
- ğŸš§ Performance optimization and query tuning
- ğŸš§ Comprehensive documentation completion

**Phase 3: Future Roadmap**
- ğŸ“‹ Web scraping from Elden Ring Wiki (fextralife)
- ğŸ“‹ Data validation and enrichment
- ğŸ“‹ Real-time dashboard updates
- ğŸ“‹ Machine learning models for build recommendations

## ğŸ“š Documentation

Detailed documentation available in the `docs/` folder:
- [DATA SOURCES AND STRUCTURE.md](docs/DATA%20SOURCES%20AND%20STRUCTURE.md) - Complete data schema reference
- [DATA QUALITY ISSUES.md](docs/DATA%20QUALITY%20ISSUES%20(INITIAL%20ANALYSIS%20USING%20EXCEL).md) - Identified data quality challenges


## ğŸ™ Acknowledgments

- **Data Source**: [Elden Ring Ultimate Dataset](https://www.kaggle.com/datasets/robikscube/elden-ring-ultimate-dataset) by Robikscube on Kaggle
- **Future Data**: Planning to scrape and integrate data from [Elden Ring Wiki (fextralife)](https://eldenring.wiki.fextralife.com/)
- **Platform**: Built on Databricks Community Edition
- **Purpose**: Practical data engineering learning project


---

**Note**: This project is for educational and analytical purposes. All Elden Ring content is property of FromSoftware and Bandai Namco Entertainment.
